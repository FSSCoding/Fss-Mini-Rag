# FSS-Mini-RAG Visual Guide

> **Visual diagrams showing how the system works**  
> *Perfect for visual learners who want to understand the flow and architecture*

## Table of Contents

- [System Overview](#system-overview)
- [User Journey](#user-journey) 
- [File Processing Flow](#file-processing-flow)
- [Search Architecture](#search-architecture)
- [Installation Flow](#installation-flow)
- [Configuration System](#configuration-system)
- [System Context Integration](#system-context-integration)
- [Error Handling](#error-handling)

## System Overview

```mermaid
graph TB
    User[ğŸ‘¤ User] --> CLI[ğŸ–¥ï¸ rag-mini CLI]
    User --> TUI[ğŸ“‹ rag-tui Interface]
    
    CLI --> Index[ğŸ“ Index Project]
    CLI --> Search[ğŸ” Search Project]
    CLI --> Explore[ğŸ§  Explore Project]
    CLI --> Status[ğŸ“Š Show Status]
    
    TUI --> Index
    TUI --> Search
    TUI --> Explore
    TUI --> Config[âš™ï¸ Configuration]
    
    Index --> Files[ğŸ“„ File Discovery]
    Files --> Chunk[âœ‚ï¸ Text Chunking]
    Chunk --> Embed[ğŸ§  Generate Embeddings]
    Embed --> Store[ğŸ’¾ Vector Database]
    
    Search --> Query[â“ User Query]
    Search --> Context[ğŸ–¥ï¸ System Context]
    Query --> Vector[ğŸ¯ Vector Search]
    Query --> Keyword[ğŸ”¤ Keyword Search]
    Vector --> Combine[ğŸ”„ Hybrid Results]
    Keyword --> Combine
    Context --> Combine
    Combine --> Synthesize{Synthesis Mode?}
    
    Synthesize -->|Yes| FastLLM[âš¡ Fast Synthesis]
    Synthesize -->|No| Results[ğŸ“‹ Ranked Results]
    FastLLM --> Results
    
    Explore --> ExploreQuery[â“ Interactive Query]
    ExploreQuery --> Memory[ğŸ§  Conversation Memory]
    ExploreQuery --> Context
    Memory --> DeepLLM[ğŸ¤” Deep AI Analysis]
    Context --> DeepLLM
    Vector --> DeepLLM
    DeepLLM --> Interactive[ğŸ’¬ Interactive Response]
    
    Store --> LanceDB[(ğŸ—„ï¸ LanceDB)]
    Vector --> LanceDB
    
    Config --> YAML[ğŸ“ config.yaml]
    Status --> Manifest[ğŸ“‹ manifest.json]
    Context --> SystemInfo[ğŸ’» OS, Python, Paths]
```

## User Journey

```mermaid
journey
    title New User Experience
    section Discovery
      Copy folder: 5: User
      Run rag-mini: 3: User, System
      See auto-setup: 4: User, System
    section First Use
      Choose directory: 5: User
      Index project: 4: User, System
      Try first search: 5: User, System
      Get results: 5: User, System
    section Learning
      Read documentation: 4: User
      Try TUI interface: 5: User, System
      Experiment with queries: 5: User
    section Mastery
      Use CLI directly: 5: User
      Configure settings: 4: User
      Integrate in workflow: 5: User
```

## File Processing Flow

```mermaid
flowchart TD
    Start([ğŸš€ Start Indexing]) --> Discover[ğŸ” Discover Files]
    
    Discover --> Filter{ğŸ“‹ Apply Filters}
    Filter --> Skip[â­ï¸ Skip Excluded]
    Filter --> Check{ğŸ“ Check Size}
    
    Check --> Large[ğŸ“š Large File<br/>Stream Processing]
    Check --> Small[ğŸ“„ Normal File<br/>Load in Memory]
    
    Large --> Stream[ğŸŒŠ Stream Reader]
    Small --> Read[ğŸ“– File Reader]
    
    Stream --> Language{ğŸ”¤ Detect Language}
    Read --> Language
    
    Language --> Python[ğŸ Python AST<br/>Function/Class Chunks]
    Language --> Markdown[ğŸ“ Markdown<br/>Header-based Chunks]
    Language --> Code[ğŸ’» Other Code<br/>Smart Chunking]
    Language --> Text[ğŸ“„ Plain Text<br/>Fixed-size Chunks]
    
    Python --> Validate{âœ… Quality Check}
    Markdown --> Validate
    Code --> Validate
    Text --> Validate
    
    Validate --> Reject[âŒ Too Small/Short]
    Validate --> Accept[âœ… Good Chunk]
    
    Accept --> Embed[ğŸ§  Generate Embedding]
    Embed --> Store[ğŸ’¾ Store in Database]
    
    Store --> More{ğŸ”„ More Files?}
    More --> Discover
    More --> Done([âœ… Indexing Complete])
    
    style Start fill:#e1f5fe
    style Done fill:#e8f5e8
    style Reject fill:#ffebee
```

## Search Architecture

```mermaid
graph TB
    Query[â“ User Query: "user authentication"] --> Process[ğŸ”§ Query Processing]
    
    Process --> Vector[ğŸ¯ Vector Search Path]
    Process --> Keyword[ğŸ”¤ Keyword Search Path]
    
    subgraph "Vector Pipeline"
        Vector --> Embed[ğŸ§  Query â†’ Embedding]
        Embed --> Similar[ğŸ“Š Find Similar Vectors]
        Similar --> VScore[ğŸ“ˆ Similarity Scores]
    end
    
    subgraph "Keyword Pipeline" 
        Keyword --> Terms[ğŸ”¤ Extract Terms]
        Terms --> BM25[ğŸ“Š BM25 Algorithm]
        BM25 --> KScore[ğŸ“ˆ Keyword Scores]
    end
    
    subgraph "Hybrid Combination"
        VScore --> Merge[ğŸ”„ Merge Results]
        KScore --> Merge
        Merge --> Rank[ğŸ“Š Advanced Ranking]
        Rank --> Boost[â¬†ï¸ Apply Boosts]
    end
    
    subgraph "Ranking Factors"
        Boost --> Exact[ğŸ¯ Exact Matches +30%]
        Boost --> Name[ğŸ·ï¸ Function Names +20%] 
        Boost --> Length[ğŸ“ Content Length]
        Boost --> Type[ğŸ“ Chunk Type]
    end
    
    Exact --> Final[ğŸ“‹ Final Results]
    Name --> Final
    Length --> Final
    Type --> Final
    
    Final --> Display[ğŸ–¥ï¸ Display to User]
    
    style Query fill:#e3f2fd
    style Final fill:#e8f5e8
    style Display fill:#f3e5f5
```

## Installation Flow

```mermaid
flowchart TD
    Start([ğŸ‘¤ User Copies Folder]) --> Run[âš¡ Run rag-mini]
    
    Run --> Check{ğŸ” Check Virtual Environment}
    Check --> Found[âœ… Found Working venv] 
    Check --> Missing[âŒ No venv Found]
    
    Found --> Ready[ğŸš€ Ready to Use]
    
    Missing --> Warning[âš ï¸ Show Experimental Warning]
    Warning --> Auto{ğŸ¤– Try Auto-setup?}
    
    Auto --> Python{ğŸ Python Available?}
    Python --> No[âŒ No Python] --> Fail
    Python --> Yes[âœ… Python Found] --> Create{ğŸ—ï¸ Create venv}
    
    Create --> Failed[âŒ Creation Failed] --> Fail
    Create --> Success[âœ… venv Created] --> Install{ğŸ“¦ Install Deps}
    
    Install --> InstallFail[âŒ Install Failed] --> Fail
    Install --> InstallOK[âœ… Deps Installed] --> Ready
    
    Fail[ğŸ’” Graceful Failure] --> Help[ğŸ“– Show Installation Help]
    Help --> Manual[ğŸ”§ Manual Instructions]
    Help --> Installer[ğŸ“‹ ./install_mini_rag.sh]
    Help --> Issues[ğŸš¨ Common Issues + Solutions]
    
    Ready --> Index[ğŸ“ Index Projects]
    Ready --> Search[ğŸ” Search Code]
    Ready --> TUI[ğŸ“‹ Interactive Interface]
    
    style Start fill:#e1f5fe
    style Ready fill:#e8f5e8
    style Warning fill:#fff3e0
    style Fail fill:#ffebee
    style Help fill:#f3e5f5
```

## Configuration System

```mermaid
graph LR
    subgraph "Configuration Sources"
        Default[ğŸ­ Built-in Defaults]
        Global[ğŸŒ ~/.config/fss-mini-rag/config.yaml]
        Project[ğŸ“ project/.mini-rag/config.yaml]
        Env[ğŸ”§ Environment Variables]
    end
    
    subgraph "Hierarchical Loading"
        Default --> Merge1[ğŸ”„ Merge]
        Global --> Merge1
        Merge1 --> Merge2[ğŸ”„ Merge]
        Project --> Merge2
        Merge2 --> Merge3[ğŸ”„ Merge]
        Env --> Merge3
    end
    
    Merge3 --> Final[âš™ï¸ Final Configuration]
    
    subgraph "Configuration Areas"
        Final --> Chunking[âœ‚ï¸ Text Chunking<br/>â€¢ Max/min sizes<br/>â€¢ Strategy (semantic/fixed)]
        Final --> Embedding[ğŸ§  Embeddings<br/>â€¢ Ollama settings<br/>â€¢ Fallback methods]
        Final --> Search[ğŸ” Search Behavior<br/>â€¢ Result limits<br/>â€¢ Similarity thresholds]
        Final --> Files[ğŸ“„ File Processing<br/>â€¢ Include/exclude patterns<br/>â€¢ Size limits]
        Final --> Streaming[ğŸŒŠ Large File Handling<br/>â€¢ Streaming threshold<br/>â€¢ Memory management]
    end
    
    style Default fill:#e3f2fd
    style Final fill:#e8f5e8
    style Chunking fill:#f3e5f5
    style Embedding fill:#fff3e0
```

## Error Handling

```mermaid
flowchart TD
    Operation[ğŸ”§ Any Operation] --> Try{ğŸ¯ Try Primary Method}
    
    Try --> Success[âœ… Success] --> Done[âœ… Complete]
    Try --> Fail[âŒ Primary Failed] --> Fallback{ğŸ”„ Fallback Available?}
    
    Fallback --> NoFallback[âŒ No Fallback] --> Error
    Fallback --> HasFallback[âœ… Try Fallback] --> FallbackTry{ğŸ¯ Try Fallback}
    
    FallbackTry --> FallbackOK[âœ… Fallback Success] --> Warn[âš ï¸ Log Warning] --> Done
    FallbackTry --> FallbackFail[âŒ Fallback Failed] --> Error
    
    Error[ğŸ’” Handle Error] --> Log[ğŸ“ Log Details]
    Log --> UserMsg[ğŸ‘¤ Show User Message]
    UserMsg --> Suggest[ğŸ’¡ Suggest Solutions]
    Suggest --> Exit[ğŸšª Graceful Exit]
    
    subgraph "Fallback Examples"
        direction TB
        Ollama[ğŸ¤– Ollama Embeddings] -.-> ML[ğŸ§  ML Models]
        ML -.-> Hash[#ï¸âƒ£ Hash-based]
        
        VenvFail[âŒ Venv Creation] -.-> SystemPy[ğŸ System Python]
        
        LargeFile[ğŸ“š Large File] -.-> Stream[ğŸŒŠ Streaming Mode]
        Stream -.-> Skip[â­ï¸ Skip File]
    end
    
    style Success fill:#e8f5e8
    style Fail fill:#ffebee
    style Warn fill:#fff3e0
    style Error fill:#ffcdd2
```

## System Context Integration

```mermaid
graph LR
    subgraph "System Detection"
        OS[ğŸ–¥ï¸ Operating System]
        Python[ğŸ Python Version] 
        Project[ğŸ“ Project Path]
        
        OS --> Windows[Windows: rag.bat]
        OS --> Linux[Linux: ./rag-mini]
        OS --> macOS[macOS: ./rag-mini]
    end
    
    subgraph "Context Collection"
        Collect[ğŸ” Collect Context]
        OS --> Collect
        Python --> Collect
        Project --> Collect
        
        Collect --> Format[ğŸ“ Format Context]
        Format --> Limit[âœ‚ï¸ Limit to 200 chars]
    end
    
    subgraph "AI Integration"
        UserQuery[â“ User Query] 
        SearchResults[ğŸ“‹ Search Results]
        SystemContext[ğŸ’» System Context]
        
        UserQuery --> Prompt[ğŸ“ Build Prompt]
        SearchResults --> Prompt
        SystemContext --> Prompt
        
        Prompt --> AI[ğŸ¤– LLM Processing]
        AI --> Response[ğŸ’¬ Contextual Response]
    end
    
    subgraph "Enhanced Responses"
        Response --> Commands[ğŸ’» OS-specific commands]
        Response --> Paths[ğŸ“‚ Correct path formats]
        Response --> Tips[ğŸ’¡ Platform-specific tips]
    end
    
    Format --> SystemContext
    
    style SystemContext fill:#e3f2fd
    style Response fill:#f3e5f5
    style Commands fill:#e8f5e8
```

*System context helps the AI provide better, platform-specific guidance without compromising privacy*

## Architecture Layers

```mermaid
graph TB
    subgraph "User Interfaces"
        CLI[ğŸ–¥ï¸ Command Line Interface]
        TUI[ğŸ“‹ Text User Interface]
        Python[ğŸ Python API]
    end
    
    subgraph "Core Logic Layer"
        Router[ğŸš Command Router]
        Indexer[ğŸ“ Project Indexer]
        Searcher[ğŸ” Code Searcher]
        Config[âš™ï¸ Config Manager]
    end
    
    subgraph "Processing Layer"
        Chunker[âœ‚ï¸ Code Chunker]
        Embedder[ğŸ§  Ollama Embedder]
        Watcher[ğŸ‘ï¸ File Watcher]
        PathHandler[ğŸ“‚ Path Handler]
    end
    
    subgraph "Storage Layer"
        LanceDB[(ğŸ—„ï¸ Vector Database)]
        Manifest[ğŸ“‹ Index Manifest]
        ConfigFile[ğŸ“ Configuration Files]
    end
    
    CLI --> Router
    TUI --> Router
    Python --> Router
    
    Router --> Indexer
    Router --> Searcher
    Router --> Config
    
    Indexer --> Chunker
    Indexer --> Embedder
    Searcher --> Embedder
    Config --> PathHandler
    
    Chunker --> LanceDB
    Embedder --> LanceDB
    Indexer --> Manifest
    Config --> ConfigFile
    
    Watcher --> Indexer
    
    style CLI fill:#e3f2fd
    style TUI fill:#e3f2fd
    style Python fill:#e3f2fd
    style LanceDB fill:#fff3e0
    style Manifest fill:#fff3e0
    style ConfigFile fill:#fff3e0
```

---

*These diagrams provide a complete visual understanding of how FSS-Mini-RAG works under the hood, perfect for visual learners and developers who want to extend the system.*